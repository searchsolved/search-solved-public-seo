{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhH4avqmoGM1yh2+b7w4wZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6262f203880b4a64ad8367c61ad9d778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "all-MiniLM-L6-v2 (Score: 58.80, Speed: 14200)",
              "all-mpnet-base-v2 (Score: 63.30, Speed: 2800)",
              "multi-qa-mpnet-base-dot-v1 (Score: 62.18, Speed: 2800)",
              "all-distilroberta-v1 (Score: 59.84, Speed: 4000)",
              "all-MiniLM-L12-v2 (Score: 59.76, Speed: 7500)",
              "multi-qa-distilbert-cos-v1 (Score: 59.41, Speed: 4000)",
              "multi-qa-MiniLM-L6-cos-v1 (Score: 58.08, Speed: 14200)",
              "paraphrase-multilingual-mpnet-base-v2 (Score: 53.75, Speed: 2500)",
              "paraphrase-albert-small-v2 (Score: 52.25, Speed: 5000)",
              "paraphrase-multilingual-MiniLM-L12-v2 (Score: 51.72, Speed: 7500)",
              "paraphrase-MiniLM-L3-v2 (Score: 50.74, Speed: 19000)",
              "distiluse-base-multilingual-cased-v1 (Score: 45.59, Speed: 4000)",
              "distiluse-base-multilingual-cased-v2 (Score: 43.77, Speed: 4000)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_e02eccf025414912a3d2fe3f3132b59c",
            "style": "IPY_MODEL_fe4747f5041a48438992e1b4253e3a27"
          }
        },
        "e02eccf025414912a3d2fe3f3132b59c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4747f5041a48438992e1b4253e3a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/searchsolved/search-solved-public-seo/blob/main/portfolio/bert-semantic-interlinker/google-colab/BERT_Semantic_Interlinker_11th_December_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Interlinker - Pairwise Matching - 11th December 2023\n",
        "### by @LeeFootSEO | https://leefoot.co.uk\n",
        "\n",
        "## How to use:\n",
        "1.  Upload a crawl file Screaming Frog. The only two mandatory columns are Address and H1-1. (You can use other crawlers / URLs lists, as long as they contain a H1 and are named as above).\n",
        "2.  Remember to choose a GPU runtime (Runtime > Change Runtime Type) or be prepared for a LONG wait!\n",
        "3. This script uses pair-wise matching, essentially it matches row by row against the entire dataset. The workload will increase exponentially the larger the input file.\n",
        "4. Reach out if you need this running as a managed service either via my website or hello@leefoot.co.uk"
      ],
      "metadata": {
        "id": "EOLpB-3DTLZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTYs9LuWIOsW",
        "outputId": "8ab32a88-7d6c-480c-cc71-6d8389a4e452"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61.4/86.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=cb1bccfc2057dbbaf3f3501b82fc06e71903ae54f42dbbfa434c96679d5e7ae2\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GTHvS-lNBIs7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the drop down menu below to choose the desired Sentence Transformer.\n",
        "The default is 'all-MiniLM-L6-v2' which is a good balance between speed and performance."
      ],
      "metadata": {
        "id": "SibBZOzWVXq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_with_scores_and_speed = {\n",
        "    'all-MiniLM-L6-v2': {'score': '58.80', 'speed': '14200'},  # good balance of semantic score and speed\n",
        "    'all-mpnet-base-v2': {'score': '63.30', 'speed': '2800'},\n",
        "    'multi-qa-mpnet-base-dot-v1': {'score': '62.18', 'speed': '2800'},\n",
        "    'all-distilroberta-v1': {'score': '59.84', 'speed': '4000'},\n",
        "    'all-MiniLM-L12-v2': {'score': '59.76', 'speed': '7500'},\n",
        "    'multi-qa-distilbert-cos-v1': {'score': '59.41', 'speed': '4000'},\n",
        "    'multi-qa-MiniLM-L6-cos-v1': {'score': '58.08', 'speed': '14200'},\n",
        "    'paraphrase-multilingual-mpnet-base-v2': {'score': '53.75', 'speed': '2500'},\n",
        "    'paraphrase-albert-small-v2': {'score': '52.25', 'speed': '5000'},\n",
        "    'paraphrase-multilingual-MiniLM-L12-v2': {'score': '51.72', 'speed': '7500'},\n",
        "    'paraphrase-MiniLM-L3-v2': {'score': '50.74', 'speed': '19000'},\n",
        "    'distiluse-base-multilingual-cased-v1': {'score': '45.59', 'speed': '4000'},\n",
        "    'distiluse-base-multilingual-cased-v2': {'score': '43.77', 'speed': '4000'}\n",
        "}\n",
        "\n",
        "# Create a dropdown with models, their average performance scores, and speed\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=[(f\"{model} (Score: {details['score']}, Speed: {details['speed']})\", model) for model, details in models_with_scores_and_speed.items()],\n",
        "    description='Model:',\n",
        ")\n",
        "\n",
        "display(model_dropdown)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6262f203880b4a64ad8367c61ad9d778",
            "e02eccf025414912a3d2fe3f3132b59c",
            "fe4747f5041a48438992e1b4253e3a27"
          ]
        },
        "id": "I7R1ZYdhEt8-",
        "outputId": "c9888e0c-d863-42d8-d149-5834d0f32195"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Model:', options=(('all-MiniLM-L6-v2 (Score: 58.80, Speed: 14200)', 'all-MiniLM-L6-v2'),…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6262f203880b4a64ad8367c61ad9d778"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the similarity score cutoff and the maximum number of suggestions per page using the slider below."
      ],
      "metadata": {
        "id": "BxyViF7WVIxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slider for Minimum Similarity (as a percentage)\n",
        "min_similarity_slider = widgets.FloatSlider(\n",
        "    value=80,  # Default value in percentage\n",
        "    min=0,     # Minimum value\n",
        "    max=100,   # Maximum value\n",
        "    step=1,    # Step size\n",
        "    description='Min Similarity (%):',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout={'width': '50%'}\n",
        ")\n",
        "\n",
        "# Slider for Maximum Suggestions Per Page\n",
        "max_suggestions_slider = widgets.IntSlider(\n",
        "    value=10,  # Default value\n",
        "    min=1,     # Minimum value\n",
        "    max=50,    # Maximum value\n",
        "    step=1,    # Step size\n",
        "    description='Max Suggestions/Page:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout={'width': '50%'}\n",
        ")\n",
        "\n",
        "display(min_similarity_slider, max_suggestions_slider)"
      ],
      "metadata": {
        "id": "qtuxxOJ7VV1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_SIMILARITY = min_similarity_slider.value / 100.0  # Convert percentage to decimal\n",
        "MAX_SUGGESTIONS_PER_PAGE = max_suggestions_slider.value"
      ],
      "metadata": {
        "id": "UyFGshLTVIW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically detect CUDA\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "if DEVICE == 'cpu':\n",
        "    # Prints a warning message in red\n",
        "    warning_message = \"Warning: CUDA is not available. The script will run on the CPU, which may be much slower.\"\n",
        "    print(colored(warning_message, 'red'))\n",
        "    warnings.warn(warning_message)\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDLt2oMjBXIF",
        "outputId": "97ad9fbe-e465-4f7b-c21a-af1c788744eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "input_filename = next(iter(uploaded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "dmlS3vbsECid",
        "outputId": "38d1421d-de10-461e-9119-26673c3eaeb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-71d427e5-f841-4245-8b13-e2d762abc824\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-71d427e5-f841-4245-8b13-e2d762abc824\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving live_demo.csv to live_demo.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Definitions"
      ],
      "metadata": {
        "id": "l8A147FjE8W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_clean_data(filepath):\n",
        "    \"\"\"\n",
        "    Reads and cleans a DataFrame from a specified CSV file.\n",
        "\n",
        "    This function reads a CSV file into a DataFrame, retains rows where the 'H1-1' column is not NaN,\n",
        "    and removes rows where the 'H1-1' column starts with \"All\".\n",
        "\n",
        "    Args:\n",
        "    filepath (str): The file path of the CSV file to be read.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: A cleaned DataFrame.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(filepath, encoding=\"utf-8\")\n",
        "    df = df[df[\"H1-1\"].notna()]\n",
        "    df = df[~df[\"H1-1\"].str.contains(\"^All \", na=False, regex=True)]\n",
        "    return df\n",
        "\n",
        "\n",
        "def precompute_embeddings(df):\n",
        "    \"\"\"\n",
        "    Computes embeddings for text data in a DataFrame using a specified transformer model.\n",
        "\n",
        "    This function encodes the 'H1-1' column of a DataFrame using a transformer model\n",
        "    specified in the global model_dropdown variable.\n",
        "\n",
        "    Args:\n",
        "    df (DataFrame): The DataFrame containing the text data in its 'H1-1' column.\n",
        "\n",
        "    Returns:\n",
        "    Tuple: A tuple containing the computed embeddings and the list of original texts.\n",
        "    \"\"\"\n",
        "    embedding_model = SentenceTransformer(model_dropdown.value, device=DEVICE)\n",
        "    to_list = list(df['H1-1'])\n",
        "    to_embeddings = embedding_model.encode(to_list)\n",
        "    return to_embeddings, to_list\n",
        "\n",
        "\n",
        "def find_matches(from_list, to_list, to_embeddings, embedding_model):\n",
        "    \"\"\"\n",
        "    Finds matches for each item in the from_list against the to_list based on cosine similarity.\n",
        "\n",
        "    This function computes the cosine similarity between the embeddings of each item in from_list\n",
        "    and all items in to_list, then selects matches based on a minimum similarity threshold.\n",
        "\n",
        "    Args:\n",
        "    from_list (list): A list of strings to find matches for.\n",
        "    to_list (list): A list of strings to match against.\n",
        "    to_embeddings (ndarray): The precomputed embeddings for the to_list.\n",
        "    embedding_model (SentenceTransformer): The transformer model used for generating embeddings.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: A DataFrame with columns 'From', 'To', and 'Similarity' for each match found.\n",
        "    \"\"\"\n",
        "    dfs = []\n",
        "    with tqdm(total=len(from_list), desc=\"Finding Matches\") as pbar:\n",
        "        for kw in from_list:\n",
        "            kw_embedding = embedding_model.encode([kw])\n",
        "            similarities = cosine_similarity(kw_embedding, to_embeddings)[0]\n",
        "            matches = np.where(similarities >= MIN_SIMILARITY)[0]\n",
        "            matches = matches[similarities[matches].argsort()[::-1]]\n",
        "            if len(matches) > 0:\n",
        "                match_indices = matches[:MAX_SUGGESTIONS_PER_PAGE]\n",
        "                df = pd.DataFrame({\n",
        "                    'From': [kw] * len(match_indices),\n",
        "                    'To': [to_list[j] for j in match_indices],\n",
        "                    'Similarity': [similarities[j] for j in match_indices]\n",
        "                })\n",
        "                dfs.append(df)\n",
        "            pbar.update(1)\n",
        "    return pd.concat(dfs) if dfs else pd.DataFrame()\n",
        "\n",
        "\n",
        "def merge_url_data(df_final, df_h1_urls):\n",
        "    \"\"\"\n",
        "    Merges URL data into the final DataFrame.\n",
        "\n",
        "    This function adds 'Source URL' and 'Destination URL' columns to the final DataFrame\n",
        "    by merging with the df_h1_urls DataFrame based on the 'From' and 'To' columns.\n",
        "\n",
        "    Args:\n",
        "    df_final (DataFrame): The DataFrame containing the matching results.\n",
        "    df_h1_urls (DataFrame): The DataFrame containing the URL data.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: The merged DataFrame with added URL columns.\n",
        "    \"\"\"\n",
        "    df_final = pd.merge(df_final, df_h1_urls, left_on=\"From\", right_on=\"H1-1\", how=\"left\")\n",
        "    df_final = df_final.rename(columns={\"Address\": \"Source URL\"})\n",
        "    del df_final['H1-1']\n",
        "    df_final = pd.merge(df_final, df_h1_urls, left_on=\"To\", right_on=\"H1-1\", how=\"left\")\n",
        "    df_final = df_final.rename(columns={\"Address\": \"Destination URL\"})\n",
        "    del df_final['H1-1']\n",
        "    return df_final\n",
        "\n",
        "\n",
        "def process_final_df(df_final):\n",
        "    \"\"\"\n",
        "    Processes the final DataFrame to format and filter the data.\n",
        "\n",
        "    This function removes duplicates, sorts, groups, and filters the DataFrame based on\n",
        "    specified criteria such as similarity threshold and maximum suggestions per page.\n",
        "\n",
        "    Args:\n",
        "    df_final (DataFrame): The DataFrame to be processed.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: The processed DataFrame.\n",
        "    \"\"\"\n",
        "    df_final.drop_duplicates(subset=[\"Source URL\", \"Destination URL\"], keep=\"first\", inplace=True)\n",
        "    df_final = df_final.rename(columns={\"From\": \"Source H1\", \"To\": \"Destination H1\"})\n",
        "    df_final = df_final[[\"Source H1\", \"Destination H1\", \"Similarity\", \"Source URL\", \"Destination URL\"]]\n",
        "    df_final.sort_values([\"Source H1\", \"Similarity\"], ascending=[True, False], inplace=True)\n",
        "    df_final = df_final.groupby(['Source H1']).head(MAX_SUGGESTIONS_PER_PAGE)\n",
        "    df_final = df_final[df_final.Similarity > MIN_SIMILARITY]\n",
        "    df_final['Match'] = df_final['Source H1'] == df_final['Destination H1']\n",
        "    df_final = df_final[df_final.Match == False]\n",
        "    del df_final['Match']\n",
        "    df_final['Similarity'] = df_final['Similarity'].round(2)\n",
        "    return df_final"
      ],
      "metadata": {
        "id": "qslDb7K0BZRE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Matches\n",
        "## Remember to Enable GPU Processing or this will take an enternity to complete!"
      ],
      "metadata": {
        "id": "QFRDah4fFFvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and clean data\n",
        "df = read_and_clean_data(input_filename)\n",
        "\n",
        "# Extract relevant data for matching\n",
        "df_h1_urls = df[['Address', 'H1-1']]\n",
        "from_list = list(df['H1-1'])  # List of items to find matches for\n",
        "\n",
        "# Precompute embeddings for the 'to' list\n",
        "to_embeddings, to_list = precompute_embeddings(df)\n",
        "\n",
        "# Initialize the Sentence Transformer Model\n",
        "embedding_model = SentenceTransformer(model_dropdown.value, device=DEVICE)\n",
        "\n",
        "# Now call the find_matches function\n",
        "df_matches = find_matches(from_list, to_list, to_embeddings, embedding_model)"
      ],
      "metadata": {
        "id": "oXj10xT1LO5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge URL data and process the final DataFrame\n",
        "df_final = merge_url_data(df_matches, df_h1_urls)\n",
        "df_final_processed = process_final_df(df_final)\n",
        "\n",
        "# Save and download the final processed DataFrame\n",
        "output_filename = 'bert_clustered_results.csv'\n",
        "df_final_processed.to_csv(output_filename, index=False)\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1wJae0miG4eO",
        "outputId": "1fbe3ad9-7cff-48a0-8ceb-c10291929ec6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_48c111d0-0ce7-4e80-ba7b-b2421a4bb2ef\", \"bert_clustered_results.csv\", 2845)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}